{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "#使用langSmith追踪过程, 注意langSmith只有免费5k次调用/月\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = 'xxx'\n",
    "os.environ['ZHIPUAI_API_KEY'] = 'xxx'\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "import logging\n",
    "\n",
    "# 设置日志级别\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# 问题：如何评测embedding模型的性能？\n",
    "gen_model = ChatZhipuAI(\n",
    "    model=\"glm-4-plus\",\n",
    ")\n",
    "embedding_model = ZhipuAIEmbeddings(\n",
    "    model = 'embedding-3',\n",
    "    dimensions=2048\n",
    ")\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_community.document_loaders.parsers import GrobidParser\n",
    "from langchain_community.document_loaders.generic import GenericLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyihang/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_community/document_loaders/parsers/grobid.py:53: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(xml_data, \"lxml\")\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = '/Users/liyihang/Documents/大模型+微调'\n",
    "\n",
    "loader = GenericLoader.from_filesystem(\n",
    "            pdf_dir,\n",
    "            glob=\"*\",\n",
    "            suffixes=[\".pdf\"],\n",
    "            parser= GrobidParser(segment_sentences=False)\n",
    "        )\n",
    "docs = loader.load()\n",
    "filter_docs = [doc for doc in docs if len(doc.page_content.split(' '))<30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata包括: dict_keys(['text', 'para', 'bboxes', 'pages', 'section_title', 'section_number', 'paper_title', 'file_path', 'pub_time'])\n",
      "文档所属论文: COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning\n",
      "文档所属章节: Abstract\n",
      "文档所属章节编号:0, 所属论文页码:(1, 1), 文件路径:/Users/liyihang/Documents/大模型+微调/COIG-COIA.pdf\n",
      "发表时间:N/A\n"
     ]
    }
   ],
   "source": [
    "# 展示一下docs的内容\n",
    "print(\"metadata包括:\", docs[0].metadata.keys())\n",
    "print(\"文档所属论文:\",docs[0].metadata['paper_title'])\n",
    "print(\"文档所属章节:\",docs[0].metadata['section_title'])\n",
    "print(f\"文档所属章节编号:{docs[0].metadata['section_number']}, 所属论文页码:{docs[0].metadata['pages']}, 文件路径:{docs[0].metadata['file_path']}\")\n",
    "print(f\"发表时间:{docs[0].metadata['pub_time']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取docs metadata中的abstract， 作为一级摘要文档，方便查询，metadata为paper_title, pub_time\n",
    "prev_paper_title = ''\n",
    "abstract_docs = []\n",
    "for doc in docs:\n",
    "    if doc.metadata['paper_title'] != prev_paper_title:\n",
    "        #新的文章，提取abstract\n",
    "        prev_paper_title = doc.metadata['paper_title']\n",
    "        asb_doc = Document(\n",
    "            page_content=prev_paper_title + '\\n' + doc.page_content,  # 文本内容\n",
    "            metadata={\"paper_title\": prev_paper_title, \"pub_time\":doc.metadata['pub_time']}  # 元数据\n",
    "        )\n",
    "        abstract_docs.append(asb_doc)\n",
    "    else:\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name='cl100k_base', chunk_size=512, chunk_overlap=32)\n",
    "all_splits = text_splitter.split_documents(filter_docs)\n",
    "def split_array(arr:list[Document], single_array_size:int)->list[list[Document]]:\n",
    "    # 使用列表切片按 single_array_size 拆分list\n",
    "    # 因为zhipuAI embedding在调用add_documents时最大允许的文档数是64，所以要分批add\n",
    "    return [arr[i:i + single_array_size] for i in range(0, len(arr), single_array_size)]\n",
    "split_docs = split_array(all_splits, 64)\n",
    "abstract_split_docs = split_array(abstract_docs, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载本地向量数据库faiss_index\n",
      "已加载本地向量数据库abstract_faiss_index\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "def calculate_md5_from_filepaths(folder_path):\n",
    "    \"\"\"\n",
    "    根据文件夹下所有文件的相对路径计算 MD5 码\n",
    "    :param folder_path: 文件夹路径\n",
    "    :return: MD5 码（字符串）\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # 获取文件的相对路径\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), folder_path)\n",
    "            filepaths.append(relative_path)\n",
    "    \n",
    "    # 按字母顺序排序文件路径\n",
    "    filepaths.sort()\n",
    "    \n",
    "    # 将所有文件路径拼接成一个字符串\n",
    "    filepaths_str = ''.join(filepaths)\n",
    "    \n",
    "    # 计算 MD5 值\n",
    "    md5_hash = hashlib.md5(filepaths_str.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    return md5_hash\n",
    "md5_value = calculate_md5_from_filepaths(pdf_dir)\n",
    "def get_faiss_index(splits_docs, md5_value, index_path, embedding_model, index_name='faiss_index'):\n",
    "    FAISS_INDEX_PATH = f\"{index_path}/{md5_value}_{index_name}\"\n",
    "    #print(f\"开始创建向量数据库：{FAISS_INDEX_PATH}\")\n",
    "    if os.path.exists(FAISS_INDEX_PATH):\n",
    "        # 加载已存在的向量数据库\n",
    "        vectordb = FAISS.load_local(\n",
    "            FAISS_INDEX_PATH,\n",
    "            embedding_model,\n",
    "            allow_dangerous_deserialization=True  # 明确允许反序列化\n",
    "        )\n",
    "        print(f\"已加载本地向量数据库{index_name}\")\n",
    "    else:\n",
    "        #index\n",
    "        for i, docs in enumerate(splits_docs):\n",
    "            if i == 0:\n",
    "                vectordb = FAISS.from_documents(documents=docs, embedding=embedding_model)\n",
    "            else:\n",
    "                vectordb.add_documents(documents=docs)\n",
    "        vectordb.save_local(FAISS_INDEX_PATH)\n",
    "    return vectordb\n",
    "\n",
    "content_vectordb = get_faiss_index(split_docs,md5_value=md5_value, index_path='/Users/liyihang/code/langchain_study/rag_agent_simple/faiss_db', embedding_model=embedding_model)\n",
    "abstract_vectordb = get_faiss_index(abstract_split_docs,md5_value=md5_value, index_path='/Users/liyihang/code/langchain_study/rag_agent_simple/faiss_db', embedding_model=embedding_model, index_name='abstract_faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve & Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "from typing import Annotated, TypedDict, Sequence\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from prompts import judge_prompt, rag_prompt, direct_prompt, choose_tool_prompt\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from functools import partial\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from custom_tools.multi_query import *\n",
    "from custom_tools.rag_fusion import *\n",
    "from custom_tools.decomposition import *\n",
    "from langchain_core.tools import Tool, InjectedToolArg, tool\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from typing import Callable\n",
    "\n",
    "retriever_store = {}\n",
    "def gen_title_filter(candidate_titles:Sequence[str]):\n",
    "    return {\"paper_title\":{\"$in\":candidate_titles}}\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def multi_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''为了缓解余弦相似度查询的局限性，生成多个语义类似但措辞不同的查询，以获取更全面的上下文\n",
    "\n",
    "    Args:\n",
    "        question (str): 用户提出的问题\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): 查询工具\n",
    "    '''\n",
    "    # 从全局字典中获取 retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_multi_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_multi_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def rag_fusion_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''生成关于用户问题的**多个方面**的查询，以提供对原始问题的**不同角度**的检索结果，把这些结果和原始查询一起进行倒数排序融合，最终返回查询到的Document。\n",
    "\n",
    "    Args:\n",
    "        question (str): 用户提出的问题\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): 查询工具\n",
    "    '''\n",
    "    # 从全局字典中获取 retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_abstract_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_abstract_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def decomposition_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''对用户提出的问题进行分解，生成多个子问题，然后分别查询，最后将查询结果进行融合。\n",
    "\n",
    "    Args:\n",
    "        question (str): 用户提出的问题\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): 查询工具\n",
    "    '''\n",
    "    # 从全局字典中获取 retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_decomposition_search(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_decomposition_search(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def create_abstract_query_tool(question:str, retriever: Annotated[VectorStoreRetriever, InjectedToolArg]):\n",
    "    '''生成关于用户问题的**多个方面**的查询，以提供对原始问题的**不同角度**的检索结果，把这些结果和原始查询一起进行倒数排序融合，最终返回查询到的Document。\n",
    "\n",
    "    Args:\n",
    "        question (str): 用户提出的问题\n",
    "        retriever (Annotated[VectorStoreRetriever, InjectedToolArg]): 查询工具\n",
    "    '''\n",
    "    query_search_func = create_abstract_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_abstract_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_tools.common import docs2str, fill_messages\n",
    "from copy import deepcopy\n",
    "from uuid import uuid4\n",
    "from langchain_core.runnables import chain\n",
    "# ===== 状态定义 =====\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    needs_rag: bool  # 标记是否需要RAG\n",
    "    query: str      # 存储检索内容\n",
    "    cur_node: str     # 记录当前节点名称\n",
    "    title_list: list[str] # 和当前问题相关的论文标题列表\n",
    "    search_type: str # 检索类型\n",
    "    search_kwargs: dict # 检索参数\n",
    "# ===== llm定义 =====\n",
    "judge_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "answer_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "tooluse_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "tools = [multi_query_tool, rag_fusion_query_tool, decomposition_query_tool]\n",
    "tooluse_llm = tooluse_llm.bind_tools(tools)\n",
    "\n",
    "def inject_retriever(ai_msg, vectordb, search_type:str, search_kwargs:dict):\n",
    "    tool_calls = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_call_copy = deepcopy(tool_call)\n",
    "        # 生成唯一的 retriever_id\n",
    "        retriever_id = str(uuid4())\n",
    "        # 创建 retriever 并存储\n",
    "        retriever = vectordb.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "        retriever_store[retriever_id] = retriever\n",
    "        # 将 retriever_id 注入参数\n",
    "        tool_call_copy[\"args\"][\"retriever_id\"] = retriever_id\n",
    "        tool_calls.append(tool_call_copy)\n",
    "    ai_msg.tool_calls = tool_calls\n",
    "    return ai_msg\n",
    "\n",
    "# ===== 节点函数 =====\n",
    "def judge_node(state: State):\n",
    "    \"\"\"判断是否需要RAG\"\"\"\n",
    "    # 构造判断提示\n",
    "    prompt = judge_prompt.format_messages(messages=state[\"messages\"])\n",
    "    response = judge_llm.invoke(prompt).content\n",
    "    #state[\"needs_rag\"] = True if \"Y\" in response.upper() else False\n",
    "    need_rag = True if \"Y\" in response.upper() else False\n",
    "    return {\"needs_rag\": need_rag, \"cur_node\":\"judge_node\"}\n",
    "\n",
    "def locate_paper(state:State):\n",
    "    abstract_retreiver = abstract_vectordb.as_retriever(search_type = state.get(\"search_type\", \"similarity_score_threshold\"), search_kwargs = state.get(\"search_kwargs\", {'k':5, 'score_threshold':0.3}))\n",
    "    abstract_docs = create_abstract_query_tool.invoke({\"question\":\"deepseek论文中都有哪些创新点?\", \"retriever\":abstract_retreiver})\n",
    "    paper_list = [doc[0].metadata['paper_title'] for doc in abstract_docs]\n",
    "    print(\"检索到相关论文：\", paper_list)\n",
    "    return {\"title_list\":paper_list, \"cur_node\":\"locate_paper\"}\n",
    "\n",
    "def select_retrieve_node(state: State):\n",
    "    \"\"\"模拟检索上下文（实际应替换为真实检索逻辑）\"\"\"\n",
    "    print(\"\\n=== 深入检索pdf... ===\")\n",
    "    prompt = choose_tool_prompt.format_messages(question=state[\"messages\"][-1].content)\n",
    "    response = tooluse_llm.invoke(prompt)\n",
    "    return {'messages':[response], \"query\":state[\"messages\"][-1].content, \"cur_node\":\"select_retrieve_node\"}\n",
    "\n",
    "def inject_tools(state: State):\n",
    "    \"\"\"注入工具\"\"\"\n",
    "    title_filter = gen_title_filter(state[\"title_list\"])\n",
    "    tool_msg = inject_retriever(ai_msg=state[\"messages\"][-1], vectordb=content_vectordb, search_type=state.get(\"search_type\", \"similarity\"), search_kwargs=state.get(\"search_kwargs\", {'k':5, 'fetch_k':50, 'filter':title_filter}))\n",
    "    return {'messages':[tool_msg], \"cur_node\":\"inject_tools\"}\n",
    "\n",
    "def answer_with_rag(state: State):\n",
    "    \"\"\"使用RAG生成回答\"\"\"\n",
    "    prompt = rag_prompt.format_messages(\n",
    "        context=state[\"messages\"][-1].content,\n",
    "        messages=fill_messages(content=state[\"query\"], role=\"user\")\n",
    "    )\n",
    "    response = answer_llm.invoke(prompt)\n",
    "    return {\"messages\": [AIMessage(response.content)], \"cur_node\":\"answer_with_rag\"}\n",
    "\n",
    "def answer_directly(state: State):\n",
    "    \"\"\"直接生成回答\"\"\"\n",
    "    prompt = direct_prompt.format_messages(messages=state[\"messages\"])\n",
    "    response = answer_llm.invoke(prompt)\n",
    "    return {\"messages\": [AIMessage(response.content)], \"cur_node\":\"answer_directly\"}\n",
    "\n",
    "def output_node(state: State):\n",
    "    return {\"cur_node\":\"end\"}\n",
    "\n",
    "retrieve_tool_node = ToolNode(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "# ===== 构建工作流 =====\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 添加节点\n",
    "workflow.add_node(\"check_exit\", judge_node)\n",
    "workflow.add_node(\"locate_paper\", locate_paper)\n",
    "workflow.add_node(\"select_retrieve\", select_retrieve_node)\n",
    "workflow.add_node(\"tools\", retrieve_tool_node)\n",
    "workflow.add_node(\"answer_rag\", answer_with_rag)\n",
    "workflow.add_node(\"answer_direct\", answer_directly)\n",
    "workflow.add_node(\"output\", output_node)\n",
    "workflow.add_node(\"inject_tools\", inject_tools)\n",
    "# 设置边\n",
    "workflow.set_entry_point(\"check_exit\")\n",
    "\n",
    "# 条件分支\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_exit\",\n",
    "    lambda state: END if \"再见！\" in str(state[\"messages\"][-1]) else (\"locate_paper\" if state[\"needs_rag\"] else \"answer_direct\")\n",
    ")\n",
    "workflow.add_edge(\"locate_paper\", \"select_retrieve\")\n",
    "workflow.add_edge(\"select_retrieve\", \"inject_tools\")\n",
    "workflow.add_conditional_edges(\"inject_tools\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"answer_rag\")\n",
    "workflow.add_edge(\"answer_rag\", \"output\")\n",
    "workflow.add_edge(\"answer_direct\", \"output\")\n",
    "workflow.add_edge(\"output\", END)\n",
    "\n",
    "# 持久化记忆\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# ===== 对话循环 =====\n",
    "def chat_loop(app):\n",
    "    print(\"论文助手：您好！我是学术论文阅读助手，请输入您的问题（输入'退出'或'exit'结束）\")\n",
    "    \n",
    "    thread_id = \"user_123\"  # 用户唯一标识，用于保存和恢复对话内容\n",
    "    while True:\n",
    "        user_input = input(\"\\n用户：\")\n",
    "        \n",
    "        # 初始化或加载对话状态\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        # 调用工作流\n",
    "        for event in app.stream(\n",
    "            {\"messages\": [HumanMessage(user_input)]},\n",
    "            config=config,\n",
    "            stream_mode=\"values\"\n",
    "        ):\n",
    "            if \"cur_node\" in event.keys() and (event[\"cur_node\"] == \"end\"):\n",
    "                event[\"messages\"][-1].pretty_print()\n",
    "                \n",
    "app = workflow.compile(checkpointer=memory)\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "\n",
    "def gen_graph_img(app):\n",
    "    try:\n",
    "        # 获取图片的二进制数据\n",
    "        png_data = app.get_graph().draw_mermaid_png()\n",
    "        \n",
    "        # 将二进制数据转换为PIL图像对象\n",
    "        image = PILImage.open(BytesIO(png_data))\n",
    "        \n",
    "        # 保存图像到指定路径\n",
    "        image.save('graph.png')  # 替换为你想保存的路径\n",
    "\n",
    "    except Exception as e:\n",
    "        # 处理可能出现的错误（例如缺少依赖）\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "gen_graph_img(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseek论文中都有哪些创新点?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseek论文中都有哪些创新点?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 生成的查询 ===\n",
      "1. **用户初始查询**: deepseek论文中都有哪些创新点?\n",
      "2. **查询1**: DeepSeek论文的主要技术创新和应用突破\n",
      "3. **查询2**: DeepSeek研究论文提出的独特算法和模型改进\n",
      "4. **查询3**: DeepSeek论文在相关领域的创新贡献和影响\n",
      "5. **查询4**: DeepSeek论文中提到的实验方法和结果创新点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "INFO:root:\n",
      "第 1 个查询没有检索到结果。\n",
      "INFO:root:\n",
      "第 2 个查询没有检索到结果。\n",
      "INFO:root:\n",
      "第 3 个查询的检索结果：\n",
      "INFO:root:检索结果：DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      "INFO:root:\n",
      "第 4 个查询没有检索到结果。\n",
      "INFO:root:\n",
      "第 5 个查询的检索结果：\n",
      "INFO:root:检索结果：DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      "/Users/liyihang/code/langchain_study/rag_agent_simple/custom_tools/common.py:55: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  (loads(doc), score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 检索分数 ===\n",
      "检索到相关论文： ['DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models']\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseek论文中都有哪些创新点?\n",
      "\n",
      "=== 深入检索pdf... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  decomposition_query_tool (call_-8891222663972289200)\n",
      " Call ID: call_-8891222663972289200\n",
      "  Args:\n",
      "    question: deepseek论文中都有哪些创新点?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  decomposition_query_tool (call_-8891222663972289200)\n",
      " Call ID: call_-8891222663972289200\n",
      "  Args:\n",
      "    question: deepseek论文中都有哪些创新点?\n",
      "    retriever_id: eef48cae-d3c4-4085-b46d-2b68d0c2d40b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: decomposition_query_tool\n",
      "\n",
      "根据提供的文档信息，DeepSeek论文（具体为\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"）中的技术和方法相比现有研究具有以下具体的创新点：\n",
      "\n",
      "### 1. 高质量的DeepSeekMath Corpus数据集\n",
      "- **多语言覆盖**：DeepSeekMath Corpus涵盖了多语言的数学内容，相比现有研究中的数据集，具有更广泛的适用性和普适性。\n",
      "- **大规模数据**：该数据集在规模上是最大的，提供了丰富的数学推理任务数据，为模型的训练和优化提供了坚实的基础。\n",
      "- **高质量验证**：通过预训练实验和数据分析，验证了DeepSeekMath Corpus的高质量，确保其在数学推理任务中的有效性和可靠性。\n",
      "\n",
      "### 2. 系统的数据分析和验证方法\n",
      "- **对比分析**：通过预训练实验，对比了DeepSeekMath Corpus与其他最近发布的数学训练数据集，验证其质量和效果，这种方法在现有研究中较少见。\n",
      "- **质量验证**：通过实验和数据分析，系统地验证了数据集的质量和覆盖范围，确保其在实际应用中的有效性。\n",
      "\n",
      "### 3. 模型结构和算法的优化\n",
      "- **结构优化**：探索和优化模型的结构，使其在数学推理任务中表现更佳，这一点在现有研究中往往被忽视。\n",
      "- **算法改进**：改进算法以提高模型的数学推理能力，特别是在处理复杂数学问题时，显示出更高的准确性和效率。\n",
      "\n",
      "### 4. 创新的技术手段\n",
      "- **梯度分区技术**：虽然这一点来自其他文档，但可能与DeepSeek论文的技术有相似之处。使用梯度分区技术在训练大规模模型时，减少内存消耗，同时保持通信量不变，这在现有研究中是一个创新点。\n",
      "\n",
      "### 总结\n",
      "DeepSeek论文通过构建高质量的多语言数学数据集、系统地进行数据分析和验证、优化模型结构和算法，以及采用创新的技术手段，显著提升了开放语言模型在数学推理方面的能力。这些创新点不仅填补了现有研究的空白，也为未来的数学推理研究和应用提供了新的思路和方法。\n",
      "\n",
      "希望这个回答对你有帮助！如果有更多问题，随时提问哦！📚🚀\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeek论文（具体指\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"）在数学推理领域的开放语言模型研究方面，提出了若干显著的创新点，具体如下：\n",
      "\n",
      "### 1. 高质量的DeepSeekMath Corpus数据集\n",
      "- **多语言覆盖性**：DeepSeekMath Corpus数据集涵盖了多种语言的数学内容，显著扩展了数据集的适用范围，相较于现有数据集，更具普适性和广泛性。\n",
      "- **大规模性**：该数据集在规模上达到了前所未有的水平，提供了丰富的数学推理任务数据，为模型的深度训练和性能优化奠定了坚实基础。\n",
      "- **质量验证**：通过系统的预训练实验和数据分析，验证了DeepSeekMath Corpus的高质量特性，确保其在数学推理任务中的有效性和可靠性。\n",
      "\n",
      "### 2. 系统的数据分析和验证方法\n",
      "- **对比分析**：通过预训练实验，对DeepSeekMath Corpus与其他近期发布的数学训练数据集进行了详细对比，验证了其质量和效果，此类方法在现有研究中较为罕见。\n",
      "- **质量验证**：通过实验和数据分析，系统地验证了数据集的质量和覆盖范围，确保其在实际应用中的有效性和广泛适用性。\n",
      "\n",
      "### 3. 模型结构和算法的优化\n",
      "- **结构优化**：对模型结构进行了深入探索和优化，使其在数学推理任务中表现出更高的性能，弥补了现有研究中对模型结构优化的忽视。\n",
      "- **算法改进**：对算法进行改进，显著提升了模型在处理复杂数学问题时的准确性和效率。\n",
      "\n",
      "### 4. 创新的技术手段\n",
      "- **梯度分区技术**：尽管此点源自其他文档，但可能与DeepSeek论文的技术思路有共通之处。采用梯度分区技术在训练大规模模型时，有效减少了内存消耗，同时保持通信量不变，这一技术在现有研究中具有显著的创新性。\n",
      "\n",
      "### 总结\n",
      "DeepSeek论文通过构建高质量的多语言数学数据集、系统地进行数据分析和验证、优化模型结构和算法，以及采用创新的技术手段，显著提升了开放语言模型在数学推理方面的能力。这些创新点不仅填补了现有研究的空白，也为未来数学推理研究和应用提供了新的理论框架和实践路径。\n",
      "\n",
      "希望此回答能够满足您的学术需求。如有进一步问题，敬请随时垂询。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeek论文（具体指\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"）在数学推理领域的开放语言模型研究方面，提出了若干显著的创新点，具体如下：\n",
      "\n",
      "### 1. 高质量的DeepSeekMath Corpus数据集\n",
      "- **多语言覆盖性**：DeepSeekMath Corpus数据集涵盖了多种语言的数学内容，显著扩展了数据集的适用范围，相较于现有数据集，更具普适性和广泛性。\n",
      "- **大规模性**：该数据集在规模上达到了前所未有的水平，提供了丰富的数学推理任务数据，为模型的深度训练和性能优化奠定了坚实基础。\n",
      "- **质量验证**：通过系统的预训练实验和数据分析，验证了DeepSeekMath Corpus的高质量特性，确保其在数学推理任务中的有效性和可靠性。\n",
      "\n",
      "### 2. 系统的数据分析和验证方法\n",
      "- **对比分析**：通过预训练实验，对DeepSeekMath Corpus与其他近期发布的数学训练数据集进行了详细对比，验证了其质量和效果，此类方法在现有研究中较为罕见。\n",
      "- **质量验证**：通过实验和数据分析，系统地验证了数据集的质量和覆盖范围，确保其在实际应用中的有效性和广泛适用性。\n",
      "\n",
      "### 3. 模型结构和算法的优化\n",
      "- **结构优化**：对模型结构进行了深入探索和优化，使其在数学推理任务中表现出更高的性能，弥补了现有研究中对模型结构优化的忽视。\n",
      "- **算法改进**：对算法进行改进，显著提升了模型在处理复杂数学问题时的准确性和效率。\n",
      "\n",
      "### 4. 创新的技术手段\n",
      "- **梯度分区技术**：尽管此点源自其他文档，但可能与DeepSeek论文的技术思路有共通之处。采用梯度分区技术在训练大规模模型时，有效减少了内存消耗，同时保持通信量不变，这一技术在现有研究中具有显著的创新性。\n",
      "\n",
      "### 总结\n",
      "DeepSeek论文通过构建高质量的多语言数学数据集、系统地进行数据分析和验证、优化模型结构和算法，以及采用创新的技术手段，显著提升了开放语言模型在数学推理方面的能力。这些创新点不仅填补了现有研究的空白，也为未来数学推理研究和应用提供了新的理论框架和实践路径。\n",
      "\n",
      "希望此回答能够满足您的学术需求。如有进一步问题，敬请随时垂询。\n"
     ]
    }
   ],
   "source": [
    "# 初始化或加载对话状态\n",
    "thread_id = \"user123\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "for event in app.stream(\n",
    "    {\"messages\": [HumanMessage(\"deepseek论文中都有哪些创新点?\")]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    #if \"cur_node\" in event.keys() and (event[\"cur_node\"] == \"end\" or event[\"cur_node\"] == \"inject_tools\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "论文助手：您好！我是学术论文阅读助手，请输入您的问题（输入'退出'或'exit'结束）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 已有知识无法回答，正在检索pdf... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='deepseek论文的创新点是什么？', additional_kwargs={}, response_metadata={}, id='ea270908-79f9-4258-a042-748cbfd13867'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"__arg1\": \"deepseek论文的创新点是什么？\"}', 'name': 'decompose_search'}, 'id': 'call_-8891208954433086323', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 492, 'total_tokens': 511}, 'model_name': 'glm-4-plus', 'finish_reason': 'tool_calls'}, id='run-ecc7f45e-4456-43b7-9330-702bc66c76df-0', tool_calls=[{'name': 'decompose_search', 'args': {'__arg1': 'deepseek论文的创新点是什么？'}, 'id': 'call_-8891208954433086323', 'type': 'tool_call'}]), ToolMessage(content='根据提供的文档信息和之前的问答对，我们可以总结出DeepSeek论文中提出的技术或方法相比现有研究的独特创新之处如下：\\n\\n### 1. **DeepSeekMath Corpus的高质量和多语言特性**\\n   - **创新点**：\\n     - **高质量**：DeepSeekMath语料库强调其高质量，这意味着其在数据准确性、完整性和适用性方面优于现有的数学训练语料库。\\n     - **多语言支持**：涵盖多语言数学内容，填补了现有语料库在多语言支持方面的空白，使得模型能够更好地处理不同语言的数学问题。\\n   - **对比现有研究**：现有数学训练语料库可能存在质量参差不齐、语言单一的问题，DeepSeekMath Corpus通过提升质量和增加多语言支持，显著提升了语料库的实用性和广泛性。\\n\\n### 2. **全面的预训练实验和比较**\\n   - **创新点**：\\n     - **系统性的比较实验**：论文通过预训练实验系统地比较了DeepSeekMath语料库与其他最新数学训练语料库的性能，提供了详实的实验数据和结果。\\n   - **对比现有研究**：许多现有研究可能缺乏系统性的比较实验，DeepSeek论文通过全面的预训练实验，提供了更可靠的证据来验证其语料库的有效性。\\n\\n### 3. **多种强化学习方法的详细推导和分析**\\n   - **创新点**：\\n     - **多样化的方法应用**：使用了SFT、RFT、Online RFT、DPO、PPO和GRPO等多种强化学习方法，展示了方法的多样性和综合性。\\n     - **详细的推导和分析**：对每种方法进行了详细的推导和分析，提供了理论上的深度和广度。\\n   - **对比现有研究**：现有研究可能仅侧重于某一种或几种强化学习方法，DeepSeek论文通过多种方法的综合应用和详细分析，提供了更全面的解决方案。\\n\\n### 4. **Direct Preference Optimization (DPO)的应用**\\n   - **创新点**：\\n     - **直接偏好优化**：DPO作为一种优化方法，直接针对模型的偏好进行优化，提升了模型的性能和效果。\\n   - **对比现有研究**：许多现有研究可能未涉及或未深入探讨DPO方法，DeepSeek论文通过引入DPO，展示了其在优化方法上的创新。\\n\\n### 5. **对未来方向的探讨**\\n   - **创新点**：\\n     - **前瞻性研究**：论文提供了关于三个组件的未来研究方向，展示了研究的持续性和前瞻性。\\n   - **对比现有研究**：许多研究可能在结论部分缺乏对未来方向的深入探讨，DeepSeek论文通过明确指出未来研究方向，为后续研究提供了指导。\\n\\n### 综合总结\\nDeepSeek论文的独特创新之处主要体现在：\\n1. **高质量、多语言的数学内容语料库**，填补了现有语料库的空白。\\n2. **全面的预训练实验和比较**，提供了系统性的验证。\\n3. **多种强化学习方法的详细推导和分析**，展示了方法的多样性和深度。\\n4. **引入Direct Preference Optimization (DPO)**，优化了模型性能。\\n5. **前瞻性的未来研究方向**，为后续研究提供了指导。\\n\\n这些创新点共同使得DeepSeek论文在推动开放语言模型在数学推理方面的能力极限上，具有显著的优势和贡献。', name='decompose_search', id='fd3f4ba5-2576-4b37-83b8-fdb68d05a67d', tool_call_id='call_-8891208954433086323')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeek论文在开放语言模型应用于数学推理领域展现了多项显著创新点，具体可概述如下：\n",
      "\n",
      "### 1. **高质量与多语言特性的DeepSeekMath Corpus构建**\n",
      "   - **创新阐述**：DeepSeekMath Corpus不仅强调数据的高质量，确保其在准确性、完整性和适用性方面超越现有语料库，而且实现了多语言覆盖，显著拓展了语料库的应用广度。\n",
      "   - **对比分析**：相较于现有语料库普遍存在的质量不一及语言单一性问题，DeepSeekMath Corpus通过提升数据质量及多语言支持，有效解决了这些局限，为跨语言数学推理研究提供了坚实基础。\n",
      "\n",
      "### 2. **系统全面的预训练实验与比较研究**\n",
      "   - **创新阐述**：论文通过设计系统性的预训练实验，对DeepSeekMath语料库与其他先进数学训练语料库进行了详尽的性能比较，提供了充分的实验数据支持。\n",
      "   - **对比分析**：现有研究往往缺乏此类系统比较，DeepSeek论文通过全面实验验证，增强了研究结果的可信度与说服力。\n",
      "\n",
      "### 3. **多种强化学习方法的综合应用与深入分析**\n",
      "   - **创新阐述**：论文综合运用了SFT、RFT、Online RFT、DPO、PPO和GRPO等多种强化学习方法，并对每种方法进行了细致的推导与分析，展示了研究方法的丰富性和理论深度。\n",
      "   - **对比分析**：相较于多数研究仅聚焦于某几种方法，DeepSeek论文的多方法综合应用及深入剖析，提供了更为全面的优化策略。\n",
      "\n",
      "### 4. **Direct Preference Optimization (DPO)的引入与应用**\n",
      "   - **创新阐述**：通过引入DPO方法，直接针对模型偏好进行优化，有效提升了模型性能。\n",
      "   - **对比分析**：现有研究较少涉及DPO或未深入探讨其应用，DeepSeek论文在此方面的探索，展现了方法创新与应用潜力。\n",
      "\n",
      "### 5. **前瞻性未来研究方向的探讨**\n",
      "   - **创新阐述**：论文不仅局限于当前研究成果，还明确指出了三个关键组件的未来研究方向，体现了研究的持续性与前瞻性。\n",
      "   - **对比分析**：相较于许多研究在结论部分对未来方向的探讨不足，DeepSeek论文的前瞻性分析为后续研究提供了明确指导。\n",
      "\n",
      "### 综合评述\n",
      "DeepSeek论文在开放语言模型数学推理能力提升方面，通过构建高质量多语言语料库、实施全面预训练实验、综合应用多种强化学习方法、引入DPO优化策略及前瞻性研究探讨，展现了多重创新点。这些创新不仅显著提升了模型性能，亦为相关领域的研究提供了新的思路和方法论指导，具有深远的学术影响与应用价值。\n",
      "论文助手：再见！\n"
     ]
    }
   ],
   "source": [
    "chat_loop(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
