{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "#ä½¿ç”¨langSmithè¿½è¸ªè¿‡ç¨‹, æ³¨æ„langSmithåªæœ‰å…è´¹5kæ¬¡è°ƒç”¨/æœˆ\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = 'xxx'\n",
    "os.environ['ZHIPUAI_API_KEY'] = 'xxx'\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_community.embeddings import ZhipuAIEmbeddings\n",
    "import logging\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—çº§åˆ«\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# é—®é¢˜ï¼šå¦‚ä½•è¯„æµ‹embeddingæ¨¡å‹çš„æ€§èƒ½ï¼Ÿ\n",
    "gen_model = ChatZhipuAI(\n",
    "    model=\"glm-4-plus\",\n",
    ")\n",
    "embedding_model = ZhipuAIEmbeddings(\n",
    "    model = 'embedding-3',\n",
    "    dimensions=2048\n",
    ")\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_community.document_loaders.parsers import GrobidParser\n",
    "from langchain_community.document_loaders.generic import GenericLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyihang/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_community/document_loaders/parsers/grobid.py:53: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(xml_data, \"lxml\")\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = '/Users/liyihang/Documents/å¤§æ¨¡å‹+å¾®è°ƒ'\n",
    "\n",
    "loader = GenericLoader.from_filesystem(\n",
    "            pdf_dir,\n",
    "            glob=\"*\",\n",
    "            suffixes=[\".pdf\"],\n",
    "            parser= GrobidParser(segment_sentences=False)\n",
    "        )\n",
    "docs = loader.load()\n",
    "filter_docs = [doc for doc in docs if len(doc.page_content.split(' '))<30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadataåŒ…æ‹¬: dict_keys(['text', 'para', 'bboxes', 'pages', 'section_title', 'section_number', 'paper_title', 'file_path', 'pub_time'])\n",
      "æ–‡æ¡£æ‰€å±è®ºæ–‡: COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning\n",
      "æ–‡æ¡£æ‰€å±ç« èŠ‚: Abstract\n",
      "æ–‡æ¡£æ‰€å±ç« èŠ‚ç¼–å·:0, æ‰€å±è®ºæ–‡é¡µç :(1, 1), æ–‡ä»¶è·¯å¾„:/Users/liyihang/Documents/å¤§æ¨¡å‹+å¾®è°ƒ/COIG-COIA.pdf\n",
      "å‘è¡¨æ—¶é—´:N/A\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºä¸€ä¸‹docsçš„å†…å®¹\n",
    "print(\"metadataåŒ…æ‹¬:\", docs[0].metadata.keys())\n",
    "print(\"æ–‡æ¡£æ‰€å±è®ºæ–‡:\",docs[0].metadata['paper_title'])\n",
    "print(\"æ–‡æ¡£æ‰€å±ç« èŠ‚:\",docs[0].metadata['section_title'])\n",
    "print(f\"æ–‡æ¡£æ‰€å±ç« èŠ‚ç¼–å·:{docs[0].metadata['section_number']}, æ‰€å±è®ºæ–‡é¡µç :{docs[0].metadata['pages']}, æ–‡ä»¶è·¯å¾„:{docs[0].metadata['file_path']}\")\n",
    "print(f\"å‘è¡¨æ—¶é—´:{docs[0].metadata['pub_time']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå–docs metadataä¸­çš„abstractï¼Œ ä½œä¸ºä¸€çº§æ‘˜è¦æ–‡æ¡£ï¼Œæ–¹ä¾¿æŸ¥è¯¢ï¼Œmetadataä¸ºpaper_title, pub_time\n",
    "prev_paper_title = ''\n",
    "abstract_docs = []\n",
    "for doc in docs:\n",
    "    if doc.metadata['paper_title'] != prev_paper_title:\n",
    "        #æ–°çš„æ–‡ç« ï¼Œæå–abstract\n",
    "        prev_paper_title = doc.metadata['paper_title']\n",
    "        asb_doc = Document(\n",
    "            page_content=prev_paper_title + '\\n' + doc.page_content,  # æ–‡æœ¬å†…å®¹\n",
    "            metadata={\"paper_title\": prev_paper_title, \"pub_time\":doc.metadata['pub_time']}  # å…ƒæ•°æ®\n",
    "        )\n",
    "        abstract_docs.append(asb_doc)\n",
    "    else:\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name='cl100k_base', chunk_size=512, chunk_overlap=32)\n",
    "all_splits = text_splitter.split_documents(filter_docs)\n",
    "def split_array(arr:list[Document], single_array_size:int)->list[list[Document]]:\n",
    "    # ä½¿ç”¨åˆ—è¡¨åˆ‡ç‰‡æŒ‰ single_array_size æ‹†åˆ†list\n",
    "    # å› ä¸ºzhipuAI embeddingåœ¨è°ƒç”¨add_documentsæ—¶æœ€å¤§å…è®¸çš„æ–‡æ¡£æ•°æ˜¯64ï¼Œæ‰€ä»¥è¦åˆ†æ‰¹add\n",
    "    return [arr[i:i + single_array_size] for i in range(0, len(arr), single_array_size)]\n",
    "split_docs = split_array(all_splits, 64)\n",
    "abstract_split_docs = split_array(abstract_docs, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“faiss_index\n",
      "å·²åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“abstract_faiss_index\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "def calculate_md5_from_filepaths(folder_path):\n",
    "    \"\"\"\n",
    "    æ ¹æ®æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„è®¡ç®— MD5 ç \n",
    "    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„\n",
    "    :return: MD5 ç ï¼ˆå­—ç¬¦ä¸²ï¼‰\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # è·å–æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), folder_path)\n",
    "            filepaths.append(relative_path)\n",
    "    \n",
    "    # æŒ‰å­—æ¯é¡ºåºæ’åºæ–‡ä»¶è·¯å¾„\n",
    "    filepaths.sort()\n",
    "    \n",
    "    # å°†æ‰€æœ‰æ–‡ä»¶è·¯å¾„æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²\n",
    "    filepaths_str = ''.join(filepaths)\n",
    "    \n",
    "    # è®¡ç®— MD5 å€¼\n",
    "    md5_hash = hashlib.md5(filepaths_str.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    return md5_hash\n",
    "md5_value = calculate_md5_from_filepaths(pdf_dir)\n",
    "def get_faiss_index(splits_docs, md5_value, index_path, embedding_model, index_name='faiss_index'):\n",
    "    FAISS_INDEX_PATH = f\"{index_path}/{md5_value}_{index_name}\"\n",
    "    #print(f\"å¼€å§‹åˆ›å»ºå‘é‡æ•°æ®åº“ï¼š{FAISS_INDEX_PATH}\")\n",
    "    if os.path.exists(FAISS_INDEX_PATH):\n",
    "        # åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“\n",
    "        vectordb = FAISS.load_local(\n",
    "            FAISS_INDEX_PATH,\n",
    "            embedding_model,\n",
    "            allow_dangerous_deserialization=True  # æ˜ç¡®å…è®¸ååºåˆ—åŒ–\n",
    "        )\n",
    "        print(f\"å·²åŠ è½½æœ¬åœ°å‘é‡æ•°æ®åº“{index_name}\")\n",
    "    else:\n",
    "        #index\n",
    "        for i, docs in enumerate(splits_docs):\n",
    "            if i == 0:\n",
    "                vectordb = FAISS.from_documents(documents=docs, embedding=embedding_model)\n",
    "            else:\n",
    "                vectordb.add_documents(documents=docs)\n",
    "        vectordb.save_local(FAISS_INDEX_PATH)\n",
    "    return vectordb\n",
    "\n",
    "content_vectordb = get_faiss_index(split_docs,md5_value=md5_value, index_path='/Users/liyihang/code/langchain_study/rag_agent_simple/faiss_db', embedding_model=embedding_model)\n",
    "abstract_vectordb = get_faiss_index(abstract_split_docs,md5_value=md5_value, index_path='/Users/liyihang/code/langchain_study/rag_agent_simple/faiss_db', embedding_model=embedding_model, index_name='abstract_faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve & Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langgraph.graph import START, MessagesState, StateGraph, END\n",
    "from typing import Annotated, TypedDict, Sequence\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from prompts import judge_prompt, rag_prompt, direct_prompt, choose_tool_prompt\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from functools import partial\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from custom_tools.multi_query import *\n",
    "from custom_tools.rag_fusion import *\n",
    "from custom_tools.decomposition import *\n",
    "from langchain_core.tools import Tool, InjectedToolArg, tool\n",
    "from langchain_core.runnables import RunnableLambda, Runnable\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from typing import Callable\n",
    "\n",
    "retriever_store = {}\n",
    "def gen_title_filter(candidate_titles:Sequence[str]):\n",
    "    return {\"paper_title\":{\"$in\":candidate_titles}}\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def multi_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''ä¸ºäº†ç¼“è§£ä½™å¼¦ç›¸ä¼¼åº¦æŸ¥è¯¢çš„å±€é™æ€§ï¼Œç”Ÿæˆå¤šä¸ªè¯­ä¹‰ç±»ä¼¼ä½†æªè¾ä¸åŒçš„æŸ¥è¯¢ï¼Œä»¥è·å–æ›´å…¨é¢çš„ä¸Šä¸‹æ–‡\n",
    "\n",
    "    Args:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): æŸ¥è¯¢å·¥å…·\n",
    "    '''\n",
    "    # ä»å…¨å±€å­—å…¸ä¸­è·å– retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_multi_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_multi_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def rag_fusion_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''ç”Ÿæˆå…³äºç”¨æˆ·é—®é¢˜çš„**å¤šä¸ªæ–¹é¢**çš„æŸ¥è¯¢ï¼Œä»¥æä¾›å¯¹åŸå§‹é—®é¢˜çš„**ä¸åŒè§’åº¦**çš„æ£€ç´¢ç»“æœï¼ŒæŠŠè¿™äº›ç»“æœå’ŒåŸå§‹æŸ¥è¯¢ä¸€èµ·è¿›è¡Œå€’æ•°æ’åºèåˆï¼Œæœ€ç»ˆè¿”å›æŸ¥è¯¢åˆ°çš„Documentã€‚\n",
    "\n",
    "    Args:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): æŸ¥è¯¢å·¥å…·\n",
    "    '''\n",
    "    # ä»å…¨å±€å­—å…¸ä¸­è·å– retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_abstract_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_abstract_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def decomposition_query_tool(question:str, retriever_id: Annotated[str, InjectedToolArg]):\n",
    "    '''å¯¹ç”¨æˆ·æå‡ºçš„é—®é¢˜è¿›è¡Œåˆ†è§£ï¼Œç”Ÿæˆå¤šä¸ªå­é—®é¢˜ï¼Œç„¶ååˆ†åˆ«æŸ¥è¯¢ï¼Œæœ€åå°†æŸ¥è¯¢ç»“æœè¿›è¡Œèåˆã€‚\n",
    "\n",
    "    Args:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "        retriever_id (Annotated[str, InjectedToolArg]): æŸ¥è¯¢å·¥å…·\n",
    "    '''\n",
    "    # ä»å…¨å±€å­—å…¸ä¸­è·å– retriever\n",
    "    retriever = retriever_store.get(retriever_id)\n",
    "    if retriever is None:\n",
    "        raise ValueError(f\"Invalid retriever_id: {retriever_id}\")\n",
    "    query_search_func = create_decomposition_search(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_decomposition_search(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def create_abstract_query_tool(question:str, retriever: Annotated[VectorStoreRetriever, InjectedToolArg]):\n",
    "    '''ç”Ÿæˆå…³äºç”¨æˆ·é—®é¢˜çš„**å¤šä¸ªæ–¹é¢**çš„æŸ¥è¯¢ï¼Œä»¥æä¾›å¯¹åŸå§‹é—®é¢˜çš„**ä¸åŒè§’åº¦**çš„æ£€ç´¢ç»“æœï¼ŒæŠŠè¿™äº›ç»“æœå’ŒåŸå§‹æŸ¥è¯¢ä¸€èµ·è¿›è¡Œå€’æ•°æ’åºèåˆï¼Œæœ€ç»ˆè¿”å›æŸ¥è¯¢åˆ°çš„Documentã€‚\n",
    "\n",
    "    Args:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "        retriever (Annotated[VectorStoreRetriever, InjectedToolArg]): æŸ¥è¯¢å·¥å…·\n",
    "    '''\n",
    "    query_search_func = create_abstract_query_chain(retriever)\n",
    "    if isinstance(query_search_func, Runnable):\n",
    "        return create_abstract_query_chain(retriever).invoke({\"question\":question})\n",
    "    elif isinstance(query_search_func, Callable):\n",
    "        return query_search_func(question)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_tools.common import docs2str, fill_messages\n",
    "from copy import deepcopy\n",
    "from uuid import uuid4\n",
    "from langchain_core.runnables import chain\n",
    "# ===== çŠ¶æ€å®šä¹‰ =====\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    needs_rag: bool  # æ ‡è®°æ˜¯å¦éœ€è¦RAG\n",
    "    query: str      # å­˜å‚¨æ£€ç´¢å†…å®¹\n",
    "    cur_node: str     # è®°å½•å½“å‰èŠ‚ç‚¹åç§°\n",
    "    title_list: list[str] # å’Œå½“å‰é—®é¢˜ç›¸å…³çš„è®ºæ–‡æ ‡é¢˜åˆ—è¡¨\n",
    "    search_type: str # æ£€ç´¢ç±»å‹\n",
    "    search_kwargs: dict # æ£€ç´¢å‚æ•°\n",
    "# ===== llmå®šä¹‰ =====\n",
    "judge_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "answer_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "tooluse_llm = ChatZhipuAI(model=\"glm-4-plus\")\n",
    "tools = [multi_query_tool, rag_fusion_query_tool, decomposition_query_tool]\n",
    "tooluse_llm = tooluse_llm.bind_tools(tools)\n",
    "\n",
    "def inject_retriever(ai_msg, vectordb, search_type:str, search_kwargs:dict):\n",
    "    tool_calls = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_call_copy = deepcopy(tool_call)\n",
    "        # ç”Ÿæˆå”¯ä¸€çš„ retriever_id\n",
    "        retriever_id = str(uuid4())\n",
    "        # åˆ›å»º retriever å¹¶å­˜å‚¨\n",
    "        retriever = vectordb.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "        retriever_store[retriever_id] = retriever\n",
    "        # å°† retriever_id æ³¨å…¥å‚æ•°\n",
    "        tool_call_copy[\"args\"][\"retriever_id\"] = retriever_id\n",
    "        tool_calls.append(tool_call_copy)\n",
    "    ai_msg.tool_calls = tool_calls\n",
    "    return ai_msg\n",
    "\n",
    "# ===== èŠ‚ç‚¹å‡½æ•° =====\n",
    "def judge_node(state: State):\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦éœ€è¦RAG\"\"\"\n",
    "    # æ„é€ åˆ¤æ–­æç¤º\n",
    "    prompt = judge_prompt.format_messages(messages=state[\"messages\"])\n",
    "    response = judge_llm.invoke(prompt).content\n",
    "    #state[\"needs_rag\"] = True if \"Y\" in response.upper() else False\n",
    "    need_rag = True if \"Y\" in response.upper() else False\n",
    "    return {\"needs_rag\": need_rag, \"cur_node\":\"judge_node\"}\n",
    "\n",
    "def locate_paper(state:State):\n",
    "    abstract_retreiver = abstract_vectordb.as_retriever(search_type = state.get(\"search_type\", \"similarity_score_threshold\"), search_kwargs = state.get(\"search_kwargs\", {'k':5, 'score_threshold':0.3}))\n",
    "    abstract_docs = create_abstract_query_tool.invoke({\"question\":\"deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\", \"retriever\":abstract_retreiver})\n",
    "    paper_list = [doc[0].metadata['paper_title'] for doc in abstract_docs]\n",
    "    print(\"æ£€ç´¢åˆ°ç›¸å…³è®ºæ–‡ï¼š\", paper_list)\n",
    "    return {\"title_list\":paper_list, \"cur_node\":\"locate_paper\"}\n",
    "\n",
    "def select_retrieve_node(state: State):\n",
    "    \"\"\"æ¨¡æ‹Ÿæ£€ç´¢ä¸Šä¸‹æ–‡ï¼ˆå®é™…åº”æ›¿æ¢ä¸ºçœŸå®æ£€ç´¢é€»è¾‘ï¼‰\"\"\"\n",
    "    print(\"\\n=== æ·±å…¥æ£€ç´¢pdf... ===\")\n",
    "    prompt = choose_tool_prompt.format_messages(question=state[\"messages\"][-1].content)\n",
    "    response = tooluse_llm.invoke(prompt)\n",
    "    return {'messages':[response], \"query\":state[\"messages\"][-1].content, \"cur_node\":\"select_retrieve_node\"}\n",
    "\n",
    "def inject_tools(state: State):\n",
    "    \"\"\"æ³¨å…¥å·¥å…·\"\"\"\n",
    "    title_filter = gen_title_filter(state[\"title_list\"])\n",
    "    tool_msg = inject_retriever(ai_msg=state[\"messages\"][-1], vectordb=content_vectordb, search_type=state.get(\"search_type\", \"similarity\"), search_kwargs=state.get(\"search_kwargs\", {'k':5, 'fetch_k':50, 'filter':title_filter}))\n",
    "    return {'messages':[tool_msg], \"cur_node\":\"inject_tools\"}\n",
    "\n",
    "def answer_with_rag(state: State):\n",
    "    \"\"\"ä½¿ç”¨RAGç”Ÿæˆå›ç­”\"\"\"\n",
    "    prompt = rag_prompt.format_messages(\n",
    "        context=state[\"messages\"][-1].content,\n",
    "        messages=fill_messages(content=state[\"query\"], role=\"user\")\n",
    "    )\n",
    "    response = answer_llm.invoke(prompt)\n",
    "    return {\"messages\": [AIMessage(response.content)], \"cur_node\":\"answer_with_rag\"}\n",
    "\n",
    "def answer_directly(state: State):\n",
    "    \"\"\"ç›´æ¥ç”Ÿæˆå›ç­”\"\"\"\n",
    "    prompt = direct_prompt.format_messages(messages=state[\"messages\"])\n",
    "    response = answer_llm.invoke(prompt)\n",
    "    return {\"messages\": [AIMessage(response.content)], \"cur_node\":\"answer_directly\"}\n",
    "\n",
    "def output_node(state: State):\n",
    "    return {\"cur_node\":\"end\"}\n",
    "\n",
    "retrieve_tool_node = ToolNode(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "# ===== æ„å»ºå·¥ä½œæµ =====\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "workflow.add_node(\"check_exit\", judge_node)\n",
    "workflow.add_node(\"locate_paper\", locate_paper)\n",
    "workflow.add_node(\"select_retrieve\", select_retrieve_node)\n",
    "workflow.add_node(\"tools\", retrieve_tool_node)\n",
    "workflow.add_node(\"answer_rag\", answer_with_rag)\n",
    "workflow.add_node(\"answer_direct\", answer_directly)\n",
    "workflow.add_node(\"output\", output_node)\n",
    "workflow.add_node(\"inject_tools\", inject_tools)\n",
    "# è®¾ç½®è¾¹\n",
    "workflow.set_entry_point(\"check_exit\")\n",
    "\n",
    "# æ¡ä»¶åˆ†æ”¯\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_exit\",\n",
    "    lambda state: END if \"å†è§ï¼\" in str(state[\"messages\"][-1]) else (\"locate_paper\" if state[\"needs_rag\"] else \"answer_direct\")\n",
    ")\n",
    "workflow.add_edge(\"locate_paper\", \"select_retrieve\")\n",
    "workflow.add_edge(\"select_retrieve\", \"inject_tools\")\n",
    "workflow.add_conditional_edges(\"inject_tools\", tools_condition)\n",
    "workflow.add_edge(\"tools\", \"answer_rag\")\n",
    "workflow.add_edge(\"answer_rag\", \"output\")\n",
    "workflow.add_edge(\"answer_direct\", \"output\")\n",
    "workflow.add_edge(\"output\", END)\n",
    "\n",
    "# æŒä¹…åŒ–è®°å¿†\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# ===== å¯¹è¯å¾ªç¯ =====\n",
    "def chat_loop(app):\n",
    "    print(\"è®ºæ–‡åŠ©æ‰‹ï¼šæ‚¨å¥½ï¼æˆ‘æ˜¯å­¦æœ¯è®ºæ–‡é˜…è¯»åŠ©æ‰‹ï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥'é€€å‡º'æˆ–'exit'ç»“æŸï¼‰\")\n",
    "    \n",
    "    thread_id = \"user_123\"  # ç”¨æˆ·å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºä¿å­˜å’Œæ¢å¤å¯¹è¯å†…å®¹\n",
    "    while True:\n",
    "        user_input = input(\"\\nç”¨æˆ·ï¼š\")\n",
    "        \n",
    "        # åˆå§‹åŒ–æˆ–åŠ è½½å¯¹è¯çŠ¶æ€\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        # è°ƒç”¨å·¥ä½œæµ\n",
    "        for event in app.stream(\n",
    "            {\"messages\": [HumanMessage(user_input)]},\n",
    "            config=config,\n",
    "            stream_mode=\"values\"\n",
    "        ):\n",
    "            if \"cur_node\" in event.keys() and (event[\"cur_node\"] == \"end\"):\n",
    "                event[\"messages\"][-1].pretty_print()\n",
    "                \n",
    "app = workflow.compile(checkpointer=memory)\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "\n",
    "def gen_graph_img(app):\n",
    "    try:\n",
    "        # è·å–å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®\n",
    "        png_data = app.get_graph().draw_mermaid_png()\n",
    "        \n",
    "        # å°†äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸ºPILå›¾åƒå¯¹è±¡\n",
    "        image = PILImage.open(BytesIO(png_data))\n",
    "        \n",
    "        # ä¿å­˜å›¾åƒåˆ°æŒ‡å®šè·¯å¾„\n",
    "        image.save('graph.png')  # æ›¿æ¢ä¸ºä½ æƒ³ä¿å­˜çš„è·¯å¾„\n",
    "\n",
    "    except Exception as e:\n",
    "        # å¤„ç†å¯èƒ½å‡ºç°çš„é”™è¯¯ï¼ˆä¾‹å¦‚ç¼ºå°‘ä¾èµ–ï¼‰\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "gen_graph_img(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ç”Ÿæˆçš„æŸ¥è¯¢ ===\n",
      "1. **ç”¨æˆ·åˆå§‹æŸ¥è¯¢**: deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n",
      "2. **æŸ¥è¯¢1**: DeepSeekè®ºæ–‡çš„ä¸»è¦æŠ€æœ¯åˆ›æ–°å’Œåº”ç”¨çªç ´\n",
      "3. **æŸ¥è¯¢2**: DeepSeekç ”ç©¶è®ºæ–‡æå‡ºçš„ç‹¬ç‰¹ç®—æ³•å’Œæ¨¡å‹æ”¹è¿›\n",
      "4. **æŸ¥è¯¢3**: DeepSeekè®ºæ–‡åœ¨ç›¸å…³é¢†åŸŸçš„åˆ›æ–°è´¡çŒ®å’Œå½±å“\n",
      "5. **æŸ¥è¯¢4**: DeepSeekè®ºæ–‡ä¸­æåˆ°çš„å®éªŒæ–¹æ³•å’Œç»“æœåˆ›æ–°ç‚¹\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.3\n",
      "INFO:root:\n",
      "ç¬¬ 1 ä¸ªæŸ¥è¯¢æ²¡æœ‰æ£€ç´¢åˆ°ç»“æœã€‚\n",
      "INFO:root:\n",
      "ç¬¬ 2 ä¸ªæŸ¥è¯¢æ²¡æœ‰æ£€ç´¢åˆ°ç»“æœã€‚\n",
      "INFO:root:\n",
      "ç¬¬ 3 ä¸ªæŸ¥è¯¢çš„æ£€ç´¢ç»“æœï¼š\n",
      "INFO:root:æ£€ç´¢ç»“æœï¼šDeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      "INFO:root:\n",
      "ç¬¬ 4 ä¸ªæŸ¥è¯¢æ²¡æœ‰æ£€ç´¢åˆ°ç»“æœã€‚\n",
      "INFO:root:\n",
      "ç¬¬ 5 ä¸ªæŸ¥è¯¢çš„æ£€ç´¢ç»“æœï¼š\n",
      "INFO:root:æ£€ç´¢ç»“æœï¼šDeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\n",
      "/Users/liyihang/code/langchain_study/rag_agent_simple/custom_tools/common.py:55: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  (loads(doc), score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== æ£€ç´¢åˆ†æ•° ===\n",
      "æ£€ç´¢åˆ°ç›¸å…³è®ºæ–‡ï¼š ['DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models']\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n",
      "\n",
      "=== æ·±å…¥æ£€ç´¢pdf... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  decomposition_query_tool (call_-8891222663972289200)\n",
      " Call ID: call_-8891222663972289200\n",
      "  Args:\n",
      "    question: deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  decomposition_query_tool (call_-8891222663972289200)\n",
      " Call ID: call_-8891222663972289200\n",
      "  Args:\n",
      "    question: deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\n",
      "    retriever_id: eef48cae-d3c4-4085-b46d-2b68d0c2d40b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: decomposition_query_tool\n",
      "\n",
      "æ ¹æ®æä¾›çš„æ–‡æ¡£ä¿¡æ¯ï¼ŒDeepSeekè®ºæ–‡ï¼ˆå…·ä½“ä¸º\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"ï¼‰ä¸­çš„æŠ€æœ¯å’Œæ–¹æ³•ç›¸æ¯”ç°æœ‰ç ”ç©¶å…·æœ‰ä»¥ä¸‹å…·ä½“çš„åˆ›æ–°ç‚¹ï¼š\n",
      "\n",
      "### 1. é«˜è´¨é‡çš„DeepSeekMath Corpusæ•°æ®é›†\n",
      "- **å¤šè¯­è¨€è¦†ç›–**ï¼šDeepSeekMath Corpusæ¶µç›–äº†å¤šè¯­è¨€çš„æ•°å­¦å†…å®¹ï¼Œç›¸æ¯”ç°æœ‰ç ”ç©¶ä¸­çš„æ•°æ®é›†ï¼Œå…·æœ‰æ›´å¹¿æ³›çš„é€‚ç”¨æ€§å’Œæ™®é€‚æ€§ã€‚\n",
      "- **å¤§è§„æ¨¡æ•°æ®**ï¼šè¯¥æ•°æ®é›†åœ¨è§„æ¨¡ä¸Šæ˜¯æœ€å¤§çš„ï¼Œæä¾›äº†ä¸°å¯Œçš„æ•°å­¦æ¨ç†ä»»åŠ¡æ•°æ®ï¼Œä¸ºæ¨¡å‹çš„è®­ç»ƒå’Œä¼˜åŒ–æä¾›äº†åšå®çš„åŸºç¡€ã€‚\n",
      "- **é«˜è´¨é‡éªŒè¯**ï¼šé€šè¿‡é¢„è®­ç»ƒå®éªŒå’Œæ•°æ®åˆ†æï¼ŒéªŒè¯äº†DeepSeekMath Corpusçš„é«˜è´¨é‡ï¼Œç¡®ä¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚\n",
      "\n",
      "### 2. ç³»ç»Ÿçš„æ•°æ®åˆ†æå’ŒéªŒè¯æ–¹æ³•\n",
      "- **å¯¹æ¯”åˆ†æ**ï¼šé€šè¿‡é¢„è®­ç»ƒå®éªŒï¼Œå¯¹æ¯”äº†DeepSeekMath Corpusä¸å…¶ä»–æœ€è¿‘å‘å¸ƒçš„æ•°å­¦è®­ç»ƒæ•°æ®é›†ï¼ŒéªŒè¯å…¶è´¨é‡å’Œæ•ˆæœï¼Œè¿™ç§æ–¹æ³•åœ¨ç°æœ‰ç ”ç©¶ä¸­è¾ƒå°‘è§ã€‚\n",
      "- **è´¨é‡éªŒè¯**ï¼šé€šè¿‡å®éªŒå’Œæ•°æ®åˆ†æï¼Œç³»ç»Ÿåœ°éªŒè¯äº†æ•°æ®é›†çš„è´¨é‡å’Œè¦†ç›–èŒƒå›´ï¼Œç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚\n",
      "\n",
      "### 3. æ¨¡å‹ç»“æ„å’Œç®—æ³•çš„ä¼˜åŒ–\n",
      "- **ç»“æ„ä¼˜åŒ–**ï¼šæ¢ç´¢å’Œä¼˜åŒ–æ¨¡å‹çš„ç»“æ„ï¼Œä½¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°æ›´ä½³ï¼Œè¿™ä¸€ç‚¹åœ¨ç°æœ‰ç ”ç©¶ä¸­å¾€å¾€è¢«å¿½è§†ã€‚\n",
      "- **ç®—æ³•æ”¹è¿›**ï¼šæ”¹è¿›ç®—æ³•ä»¥æé«˜æ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤æ‚æ•°å­¦é—®é¢˜æ—¶ï¼Œæ˜¾ç¤ºå‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚\n",
      "\n",
      "### 4. åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µ\n",
      "- **æ¢¯åº¦åˆ†åŒºæŠ€æœ¯**ï¼šè™½ç„¶è¿™ä¸€ç‚¹æ¥è‡ªå…¶ä»–æ–‡æ¡£ï¼Œä½†å¯èƒ½ä¸DeepSeekè®ºæ–‡çš„æŠ€æœ¯æœ‰ç›¸ä¼¼ä¹‹å¤„ã€‚ä½¿ç”¨æ¢¯åº¦åˆ†åŒºæŠ€æœ¯åœ¨è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹æ—¶ï¼Œå‡å°‘å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒé€šä¿¡é‡ä¸å˜ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­æ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ã€‚\n",
      "\n",
      "### æ€»ç»“\n",
      "DeepSeekè®ºæ–‡é€šè¿‡æ„å»ºé«˜è´¨é‡çš„å¤šè¯­è¨€æ•°å­¦æ•°æ®é›†ã€ç³»ç»Ÿåœ°è¿›è¡Œæ•°æ®åˆ†æå’ŒéªŒè¯ã€ä¼˜åŒ–æ¨¡å‹ç»“æ„å’Œç®—æ³•ï¼Œä»¥åŠé‡‡ç”¨åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†å¼€æ”¾è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚è¿™äº›åˆ›æ–°ç‚¹ä¸ä»…å¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œä¹Ÿä¸ºæœªæ¥çš„æ•°å­¦æ¨ç†ç ”ç©¶å’Œåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚\n",
      "\n",
      "å¸Œæœ›è¿™ä¸ªå›ç­”å¯¹ä½ æœ‰å¸®åŠ©ï¼å¦‚æœæœ‰æ›´å¤šé—®é¢˜ï¼Œéšæ—¶æé—®å“¦ï¼ğŸ“šğŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeekè®ºæ–‡ï¼ˆå…·ä½“æŒ‡\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"ï¼‰åœ¨æ•°å­¦æ¨ç†é¢†åŸŸçš„å¼€æ”¾è¯­è¨€æ¨¡å‹ç ”ç©¶æ–¹é¢ï¼Œæå‡ºäº†è‹¥å¹²æ˜¾è‘—çš„åˆ›æ–°ç‚¹ï¼Œå…·ä½“å¦‚ä¸‹ï¼š\n",
      "\n",
      "### 1. é«˜è´¨é‡çš„DeepSeekMath Corpusæ•°æ®é›†\n",
      "- **å¤šè¯­è¨€è¦†ç›–æ€§**ï¼šDeepSeekMath Corpusæ•°æ®é›†æ¶µç›–äº†å¤šç§è¯­è¨€çš„æ•°å­¦å†…å®¹ï¼Œæ˜¾è‘—æ‰©å±•äº†æ•°æ®é›†çš„é€‚ç”¨èŒƒå›´ï¼Œç›¸è¾ƒäºç°æœ‰æ•°æ®é›†ï¼Œæ›´å…·æ™®é€‚æ€§å’Œå¹¿æ³›æ€§ã€‚\n",
      "- **å¤§è§„æ¨¡æ€§**ï¼šè¯¥æ•°æ®é›†åœ¨è§„æ¨¡ä¸Šè¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æ°´å¹³ï¼Œæä¾›äº†ä¸°å¯Œçš„æ•°å­¦æ¨ç†ä»»åŠ¡æ•°æ®ï¼Œä¸ºæ¨¡å‹çš„æ·±åº¦è®­ç»ƒå’Œæ€§èƒ½ä¼˜åŒ–å¥ å®šäº†åšå®åŸºç¡€ã€‚\n",
      "- **è´¨é‡éªŒè¯**ï¼šé€šè¿‡ç³»ç»Ÿçš„é¢„è®­ç»ƒå®éªŒå’Œæ•°æ®åˆ†æï¼ŒéªŒè¯äº†DeepSeekMath Corpusçš„é«˜è´¨é‡ç‰¹æ€§ï¼Œç¡®ä¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚\n",
      "\n",
      "### 2. ç³»ç»Ÿçš„æ•°æ®åˆ†æå’ŒéªŒè¯æ–¹æ³•\n",
      "- **å¯¹æ¯”åˆ†æ**ï¼šé€šè¿‡é¢„è®­ç»ƒå®éªŒï¼Œå¯¹DeepSeekMath Corpusä¸å…¶ä»–è¿‘æœŸå‘å¸ƒçš„æ•°å­¦è®­ç»ƒæ•°æ®é›†è¿›è¡Œäº†è¯¦ç»†å¯¹æ¯”ï¼ŒéªŒè¯äº†å…¶è´¨é‡å’Œæ•ˆæœï¼Œæ­¤ç±»æ–¹æ³•åœ¨ç°æœ‰ç ”ç©¶ä¸­è¾ƒä¸ºç½•è§ã€‚\n",
      "- **è´¨é‡éªŒè¯**ï¼šé€šè¿‡å®éªŒå’Œæ•°æ®åˆ†æï¼Œç³»ç»Ÿåœ°éªŒè¯äº†æ•°æ®é›†çš„è´¨é‡å’Œè¦†ç›–èŒƒå›´ï¼Œç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚\n",
      "\n",
      "### 3. æ¨¡å‹ç»“æ„å’Œç®—æ³•çš„ä¼˜åŒ–\n",
      "- **ç»“æ„ä¼˜åŒ–**ï¼šå¯¹æ¨¡å‹ç»“æ„è¿›è¡Œäº†æ·±å…¥æ¢ç´¢å’Œä¼˜åŒ–ï¼Œä½¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ï¼Œå¼¥è¡¥äº†ç°æœ‰ç ”ç©¶ä¸­å¯¹æ¨¡å‹ç»“æ„ä¼˜åŒ–çš„å¿½è§†ã€‚\n",
      "- **ç®—æ³•æ”¹è¿›**ï¼šå¯¹ç®—æ³•è¿›è¡Œæ”¹è¿›ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ•°å­¦é—®é¢˜æ—¶çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚\n",
      "\n",
      "### 4. åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µ\n",
      "- **æ¢¯åº¦åˆ†åŒºæŠ€æœ¯**ï¼šå°½ç®¡æ­¤ç‚¹æºè‡ªå…¶ä»–æ–‡æ¡£ï¼Œä½†å¯èƒ½ä¸DeepSeekè®ºæ–‡çš„æŠ€æœ¯æ€è·¯æœ‰å…±é€šä¹‹å¤„ã€‚é‡‡ç”¨æ¢¯åº¦åˆ†åŒºæŠ€æœ¯åœ¨è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹æ—¶ï¼Œæœ‰æ•ˆå‡å°‘äº†å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒé€šä¿¡é‡ä¸å˜ï¼Œè¿™ä¸€æŠ€æœ¯åœ¨ç°æœ‰ç ”ç©¶ä¸­å…·æœ‰æ˜¾è‘—çš„åˆ›æ–°æ€§ã€‚\n",
      "\n",
      "### æ€»ç»“\n",
      "DeepSeekè®ºæ–‡é€šè¿‡æ„å»ºé«˜è´¨é‡çš„å¤šè¯­è¨€æ•°å­¦æ•°æ®é›†ã€ç³»ç»Ÿåœ°è¿›è¡Œæ•°æ®åˆ†æå’ŒéªŒè¯ã€ä¼˜åŒ–æ¨¡å‹ç»“æ„å’Œç®—æ³•ï¼Œä»¥åŠé‡‡ç”¨åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†å¼€æ”¾è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚è¿™äº›åˆ›æ–°ç‚¹ä¸ä»…å¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œä¹Ÿä¸ºæœªæ¥æ•°å­¦æ¨ç†ç ”ç©¶å’Œåº”ç”¨æä¾›äº†æ–°çš„ç†è®ºæ¡†æ¶å’Œå®è·µè·¯å¾„ã€‚\n",
      "\n",
      "å¸Œæœ›æ­¤å›ç­”èƒ½å¤Ÿæ»¡è¶³æ‚¨çš„å­¦æœ¯éœ€æ±‚ã€‚å¦‚æœ‰è¿›ä¸€æ­¥é—®é¢˜ï¼Œæ•¬è¯·éšæ—¶å‚è¯¢ã€‚\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeekè®ºæ–‡ï¼ˆå…·ä½“æŒ‡\"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models\"ï¼‰åœ¨æ•°å­¦æ¨ç†é¢†åŸŸçš„å¼€æ”¾è¯­è¨€æ¨¡å‹ç ”ç©¶æ–¹é¢ï¼Œæå‡ºäº†è‹¥å¹²æ˜¾è‘—çš„åˆ›æ–°ç‚¹ï¼Œå…·ä½“å¦‚ä¸‹ï¼š\n",
      "\n",
      "### 1. é«˜è´¨é‡çš„DeepSeekMath Corpusæ•°æ®é›†\n",
      "- **å¤šè¯­è¨€è¦†ç›–æ€§**ï¼šDeepSeekMath Corpusæ•°æ®é›†æ¶µç›–äº†å¤šç§è¯­è¨€çš„æ•°å­¦å†…å®¹ï¼Œæ˜¾è‘—æ‰©å±•äº†æ•°æ®é›†çš„é€‚ç”¨èŒƒå›´ï¼Œç›¸è¾ƒäºç°æœ‰æ•°æ®é›†ï¼Œæ›´å…·æ™®é€‚æ€§å’Œå¹¿æ³›æ€§ã€‚\n",
      "- **å¤§è§„æ¨¡æ€§**ï¼šè¯¥æ•°æ®é›†åœ¨è§„æ¨¡ä¸Šè¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æ°´å¹³ï¼Œæä¾›äº†ä¸°å¯Œçš„æ•°å­¦æ¨ç†ä»»åŠ¡æ•°æ®ï¼Œä¸ºæ¨¡å‹çš„æ·±åº¦è®­ç»ƒå’Œæ€§èƒ½ä¼˜åŒ–å¥ å®šäº†åšå®åŸºç¡€ã€‚\n",
      "- **è´¨é‡éªŒè¯**ï¼šé€šè¿‡ç³»ç»Ÿçš„é¢„è®­ç»ƒå®éªŒå’Œæ•°æ®åˆ†æï¼ŒéªŒè¯äº†DeepSeekMath Corpusçš„é«˜è´¨é‡ç‰¹æ€§ï¼Œç¡®ä¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚\n",
      "\n",
      "### 2. ç³»ç»Ÿçš„æ•°æ®åˆ†æå’ŒéªŒè¯æ–¹æ³•\n",
      "- **å¯¹æ¯”åˆ†æ**ï¼šé€šè¿‡é¢„è®­ç»ƒå®éªŒï¼Œå¯¹DeepSeekMath Corpusä¸å…¶ä»–è¿‘æœŸå‘å¸ƒçš„æ•°å­¦è®­ç»ƒæ•°æ®é›†è¿›è¡Œäº†è¯¦ç»†å¯¹æ¯”ï¼ŒéªŒè¯äº†å…¶è´¨é‡å’Œæ•ˆæœï¼Œæ­¤ç±»æ–¹æ³•åœ¨ç°æœ‰ç ”ç©¶ä¸­è¾ƒä¸ºç½•è§ã€‚\n",
      "- **è´¨é‡éªŒè¯**ï¼šé€šè¿‡å®éªŒå’Œæ•°æ®åˆ†æï¼Œç³»ç»Ÿåœ°éªŒè¯äº†æ•°æ®é›†çš„è´¨é‡å’Œè¦†ç›–èŒƒå›´ï¼Œç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚\n",
      "\n",
      "### 3. æ¨¡å‹ç»“æ„å’Œç®—æ³•çš„ä¼˜åŒ–\n",
      "- **ç»“æ„ä¼˜åŒ–**ï¼šå¯¹æ¨¡å‹ç»“æ„è¿›è¡Œäº†æ·±å…¥æ¢ç´¢å’Œä¼˜åŒ–ï¼Œä½¿å…¶åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ï¼Œå¼¥è¡¥äº†ç°æœ‰ç ”ç©¶ä¸­å¯¹æ¨¡å‹ç»“æ„ä¼˜åŒ–çš„å¿½è§†ã€‚\n",
      "- **ç®—æ³•æ”¹è¿›**ï¼šå¯¹ç®—æ³•è¿›è¡Œæ”¹è¿›ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ•°å­¦é—®é¢˜æ—¶çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚\n",
      "\n",
      "### 4. åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µ\n",
      "- **æ¢¯åº¦åˆ†åŒºæŠ€æœ¯**ï¼šå°½ç®¡æ­¤ç‚¹æºè‡ªå…¶ä»–æ–‡æ¡£ï¼Œä½†å¯èƒ½ä¸DeepSeekè®ºæ–‡çš„æŠ€æœ¯æ€è·¯æœ‰å…±é€šä¹‹å¤„ã€‚é‡‡ç”¨æ¢¯åº¦åˆ†åŒºæŠ€æœ¯åœ¨è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹æ—¶ï¼Œæœ‰æ•ˆå‡å°‘äº†å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒé€šä¿¡é‡ä¸å˜ï¼Œè¿™ä¸€æŠ€æœ¯åœ¨ç°æœ‰ç ”ç©¶ä¸­å…·æœ‰æ˜¾è‘—çš„åˆ›æ–°æ€§ã€‚\n",
      "\n",
      "### æ€»ç»“\n",
      "DeepSeekè®ºæ–‡é€šè¿‡æ„å»ºé«˜è´¨é‡çš„å¤šè¯­è¨€æ•°å­¦æ•°æ®é›†ã€ç³»ç»Ÿåœ°è¿›è¡Œæ•°æ®åˆ†æå’ŒéªŒè¯ã€ä¼˜åŒ–æ¨¡å‹ç»“æ„å’Œç®—æ³•ï¼Œä»¥åŠé‡‡ç”¨åˆ›æ–°çš„æŠ€æœ¯æ‰‹æ®µï¼Œæ˜¾è‘—æå‡äº†å¼€æ”¾è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚è¿™äº›åˆ›æ–°ç‚¹ä¸ä»…å¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œä¹Ÿä¸ºæœªæ¥æ•°å­¦æ¨ç†ç ”ç©¶å’Œåº”ç”¨æä¾›äº†æ–°çš„ç†è®ºæ¡†æ¶å’Œå®è·µè·¯å¾„ã€‚\n",
      "\n",
      "å¸Œæœ›æ­¤å›ç­”èƒ½å¤Ÿæ»¡è¶³æ‚¨çš„å­¦æœ¯éœ€æ±‚ã€‚å¦‚æœ‰è¿›ä¸€æ­¥é—®é¢˜ï¼Œæ•¬è¯·éšæ—¶å‚è¯¢ã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–æˆ–åŠ è½½å¯¹è¯çŠ¶æ€\n",
    "thread_id = \"user123\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "for event in app.stream(\n",
    "    {\"messages\": [HumanMessage(\"deepseekè®ºæ–‡ä¸­éƒ½æœ‰å“ªäº›åˆ›æ–°ç‚¹?\")]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    #if \"cur_node\" in event.keys() and (event[\"cur_node\"] == \"end\" or event[\"cur_node\"] == \"inject_tools\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®ºæ–‡åŠ©æ‰‹ï¼šæ‚¨å¥½ï¼æˆ‘æ˜¯å­¦æœ¯è®ºæ–‡é˜…è¯»åŠ©æ‰‹ï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥'é€€å‡º'æˆ–'exit'ç»“æŸï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== å·²æœ‰çŸ¥è¯†æ— æ³•å›ç­”ï¼Œæ­£åœ¨æ£€ç´¢pdf... ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='deepseekè®ºæ–‡çš„åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ', additional_kwargs={}, response_metadata={}, id='ea270908-79f9-4258-a042-748cbfd13867'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"__arg1\": \"deepseekè®ºæ–‡çš„åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\"}', 'name': 'decompose_search'}, 'id': 'call_-8891208954433086323', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 492, 'total_tokens': 511}, 'model_name': 'glm-4-plus', 'finish_reason': 'tool_calls'}, id='run-ecc7f45e-4456-43b7-9330-702bc66c76df-0', tool_calls=[{'name': 'decompose_search', 'args': {'__arg1': 'deepseekè®ºæ–‡çš„åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ'}, 'id': 'call_-8891208954433086323', 'type': 'tool_call'}]), ToolMessage(content='æ ¹æ®æä¾›çš„æ–‡æ¡£ä¿¡æ¯å’Œä¹‹å‰çš„é—®ç­”å¯¹ï¼Œæˆ‘ä»¬å¯ä»¥æ€»ç»“å‡ºDeepSeekè®ºæ–‡ä¸­æå‡ºçš„æŠ€æœ¯æˆ–æ–¹æ³•ç›¸æ¯”ç°æœ‰ç ”ç©¶çš„ç‹¬ç‰¹åˆ›æ–°ä¹‹å¤„å¦‚ä¸‹ï¼š\\n\\n### 1. **DeepSeekMath Corpusçš„é«˜è´¨é‡å’Œå¤šè¯­è¨€ç‰¹æ€§**\\n   - **åˆ›æ–°ç‚¹**ï¼š\\n     - **é«˜è´¨é‡**ï¼šDeepSeekMathè¯­æ–™åº“å¼ºè°ƒå…¶é«˜è´¨é‡ï¼Œè¿™æ„å‘³ç€å…¶åœ¨æ•°æ®å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œé€‚ç”¨æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„æ•°å­¦è®­ç»ƒè¯­æ–™åº“ã€‚\\n     - **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ¶µç›–å¤šè¯­è¨€æ•°å­¦å†…å®¹ï¼Œå¡«è¡¥äº†ç°æœ‰è¯­æ–™åº“åœ¨å¤šè¯­è¨€æ”¯æŒæ–¹é¢çš„ç©ºç™½ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ä¸åŒè¯­è¨€çš„æ•°å­¦é—®é¢˜ã€‚\\n   - **å¯¹æ¯”ç°æœ‰ç ”ç©¶**ï¼šç°æœ‰æ•°å­¦è®­ç»ƒè¯­æ–™åº“å¯èƒ½å­˜åœ¨è´¨é‡å‚å·®ä¸é½ã€è¯­è¨€å•ä¸€çš„é—®é¢˜ï¼ŒDeepSeekMath Corpusé€šè¿‡æå‡è´¨é‡å’Œå¢åŠ å¤šè¯­è¨€æ”¯æŒï¼Œæ˜¾è‘—æå‡äº†è¯­æ–™åº“çš„å®ç”¨æ€§å’Œå¹¿æ³›æ€§ã€‚\\n\\n### 2. **å…¨é¢çš„é¢„è®­ç»ƒå®éªŒå’Œæ¯”è¾ƒ**\\n   - **åˆ›æ–°ç‚¹**ï¼š\\n     - **ç³»ç»Ÿæ€§çš„æ¯”è¾ƒå®éªŒ**ï¼šè®ºæ–‡é€šè¿‡é¢„è®­ç»ƒå®éªŒç³»ç»Ÿåœ°æ¯”è¾ƒäº†DeepSeekMathè¯­æ–™åº“ä¸å…¶ä»–æœ€æ–°æ•°å­¦è®­ç»ƒè¯­æ–™åº“çš„æ€§èƒ½ï¼Œæä¾›äº†è¯¦å®çš„å®éªŒæ•°æ®å’Œç»“æœã€‚\\n   - **å¯¹æ¯”ç°æœ‰ç ”ç©¶**ï¼šè®¸å¤šç°æœ‰ç ”ç©¶å¯èƒ½ç¼ºä¹ç³»ç»Ÿæ€§çš„æ¯”è¾ƒå®éªŒï¼ŒDeepSeekè®ºæ–‡é€šè¿‡å…¨é¢çš„é¢„è®­ç»ƒå®éªŒï¼Œæä¾›äº†æ›´å¯é çš„è¯æ®æ¥éªŒè¯å…¶è¯­æ–™åº“çš„æœ‰æ•ˆæ€§ã€‚\\n\\n### 3. **å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„è¯¦ç»†æ¨å¯¼å’Œåˆ†æ**\\n   - **åˆ›æ–°ç‚¹**ï¼š\\n     - **å¤šæ ·åŒ–çš„æ–¹æ³•åº”ç”¨**ï¼šä½¿ç”¨äº†SFTã€RFTã€Online RFTã€DPOã€PPOå’ŒGRPOç­‰å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„å¤šæ ·æ€§å’Œç»¼åˆæ€§ã€‚\\n     - **è¯¦ç»†çš„æ¨å¯¼å’Œåˆ†æ**ï¼šå¯¹æ¯ç§æ–¹æ³•è¿›è¡Œäº†è¯¦ç»†çš„æ¨å¯¼å’Œåˆ†æï¼Œæä¾›äº†ç†è®ºä¸Šçš„æ·±åº¦å’Œå¹¿åº¦ã€‚\\n   - **å¯¹æ¯”ç°æœ‰ç ”ç©¶**ï¼šç°æœ‰ç ”ç©¶å¯èƒ½ä»…ä¾§é‡äºæŸä¸€ç§æˆ–å‡ ç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ŒDeepSeekè®ºæ–‡é€šè¿‡å¤šç§æ–¹æ³•çš„ç»¼åˆåº”ç”¨å’Œè¯¦ç»†åˆ†æï¼Œæä¾›äº†æ›´å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚\\n\\n### 4. **Direct Preference Optimization (DPO)çš„åº”ç”¨**\\n   - **åˆ›æ–°ç‚¹**ï¼š\\n     - **ç›´æ¥åå¥½ä¼˜åŒ–**ï¼šDPOä½œä¸ºä¸€ç§ä¼˜åŒ–æ–¹æ³•ï¼Œç›´æ¥é’ˆå¯¹æ¨¡å‹çš„åå¥½è¿›è¡Œä¼˜åŒ–ï¼Œæå‡äº†æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆæœã€‚\\n   - **å¯¹æ¯”ç°æœ‰ç ”ç©¶**ï¼šè®¸å¤šç°æœ‰ç ”ç©¶å¯èƒ½æœªæ¶‰åŠæˆ–æœªæ·±å…¥æ¢è®¨DPOæ–¹æ³•ï¼ŒDeepSeekè®ºæ–‡é€šè¿‡å¼•å…¥DPOï¼Œå±•ç¤ºäº†å…¶åœ¨ä¼˜åŒ–æ–¹æ³•ä¸Šçš„åˆ›æ–°ã€‚\\n\\n### 5. **å¯¹æœªæ¥æ–¹å‘çš„æ¢è®¨**\\n   - **åˆ›æ–°ç‚¹**ï¼š\\n     - **å‰ç»æ€§ç ”ç©¶**ï¼šè®ºæ–‡æä¾›äº†å…³äºä¸‰ä¸ªç»„ä»¶çš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œå±•ç¤ºäº†ç ”ç©¶çš„æŒç»­æ€§å’Œå‰ç»æ€§ã€‚\\n   - **å¯¹æ¯”ç°æœ‰ç ”ç©¶**ï¼šè®¸å¤šç ”ç©¶å¯èƒ½åœ¨ç»“è®ºéƒ¨åˆ†ç¼ºä¹å¯¹æœªæ¥æ–¹å‘çš„æ·±å…¥æ¢è®¨ï¼ŒDeepSeekè®ºæ–‡é€šè¿‡æ˜ç¡®æŒ‡å‡ºæœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚\\n\\n### ç»¼åˆæ€»ç»“\\nDeepSeekè®ºæ–‡çš„ç‹¬ç‰¹åˆ›æ–°ä¹‹å¤„ä¸»è¦ä½“ç°åœ¨ï¼š\\n1. **é«˜è´¨é‡ã€å¤šè¯­è¨€çš„æ•°å­¦å†…å®¹è¯­æ–™åº“**ï¼Œå¡«è¡¥äº†ç°æœ‰è¯­æ–™åº“çš„ç©ºç™½ã€‚\\n2. **å…¨é¢çš„é¢„è®­ç»ƒå®éªŒå’Œæ¯”è¾ƒ**ï¼Œæä¾›äº†ç³»ç»Ÿæ€§çš„éªŒè¯ã€‚\\n3. **å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„è¯¦ç»†æ¨å¯¼å’Œåˆ†æ**ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„å¤šæ ·æ€§å’Œæ·±åº¦ã€‚\\n4. **å¼•å…¥Direct Preference Optimization (DPO)**ï¼Œä¼˜åŒ–äº†æ¨¡å‹æ€§èƒ½ã€‚\\n5. **å‰ç»æ€§çš„æœªæ¥ç ”ç©¶æ–¹å‘**ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚\\n\\nè¿™äº›åˆ›æ–°ç‚¹å…±åŒä½¿å¾—DeepSeekè®ºæ–‡åœ¨æ¨åŠ¨å¼€æ”¾è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„èƒ½åŠ›æé™ä¸Šï¼Œå…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿å’Œè´¡çŒ®ã€‚', name='decompose_search', id='fd3f4ba5-2576-4b37-83b8-fdb68d05a67d', tool_call_id='call_-8891208954433086323')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://open.bigmodel.cn/api/paas/v4/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "DeepSeekè®ºæ–‡åœ¨å¼€æ”¾è¯­è¨€æ¨¡å‹åº”ç”¨äºæ•°å­¦æ¨ç†é¢†åŸŸå±•ç°äº†å¤šé¡¹æ˜¾è‘—åˆ›æ–°ç‚¹ï¼Œå…·ä½“å¯æ¦‚è¿°å¦‚ä¸‹ï¼š\n",
      "\n",
      "### 1. **é«˜è´¨é‡ä¸å¤šè¯­è¨€ç‰¹æ€§çš„DeepSeekMath Corpusæ„å»º**\n",
      "   - **åˆ›æ–°é˜è¿°**ï¼šDeepSeekMath Corpusä¸ä»…å¼ºè°ƒæ•°æ®çš„é«˜è´¨é‡ï¼Œç¡®ä¿å…¶åœ¨å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œé€‚ç”¨æ€§æ–¹é¢è¶…è¶Šç°æœ‰è¯­æ–™åº“ï¼Œè€Œä¸”å®ç°äº†å¤šè¯­è¨€è¦†ç›–ï¼Œæ˜¾è‘—æ‹“å±•äº†è¯­æ–™åº“çš„åº”ç”¨å¹¿åº¦ã€‚\n",
      "   - **å¯¹æ¯”åˆ†æ**ï¼šç›¸è¾ƒäºç°æœ‰è¯­æ–™åº“æ™®éå­˜åœ¨çš„è´¨é‡ä¸ä¸€åŠè¯­è¨€å•ä¸€æ€§é—®é¢˜ï¼ŒDeepSeekMath Corpusé€šè¿‡æå‡æ•°æ®è´¨é‡åŠå¤šè¯­è¨€æ”¯æŒï¼Œæœ‰æ•ˆè§£å†³äº†è¿™äº›å±€é™ï¼Œä¸ºè·¨è¯­è¨€æ•°å­¦æ¨ç†ç ”ç©¶æä¾›äº†åšå®åŸºç¡€ã€‚\n",
      "\n",
      "### 2. **ç³»ç»Ÿå…¨é¢çš„é¢„è®­ç»ƒå®éªŒä¸æ¯”è¾ƒç ”ç©¶**\n",
      "   - **åˆ›æ–°é˜è¿°**ï¼šè®ºæ–‡é€šè¿‡è®¾è®¡ç³»ç»Ÿæ€§çš„é¢„è®­ç»ƒå®éªŒï¼Œå¯¹DeepSeekMathè¯­æ–™åº“ä¸å…¶ä»–å…ˆè¿›æ•°å­¦è®­ç»ƒè¯­æ–™åº“è¿›è¡Œäº†è¯¦å°½çš„æ€§èƒ½æ¯”è¾ƒï¼Œæä¾›äº†å……åˆ†çš„å®éªŒæ•°æ®æ”¯æŒã€‚\n",
      "   - **å¯¹æ¯”åˆ†æ**ï¼šç°æœ‰ç ”ç©¶å¾€å¾€ç¼ºä¹æ­¤ç±»ç³»ç»Ÿæ¯”è¾ƒï¼ŒDeepSeekè®ºæ–‡é€šè¿‡å…¨é¢å®éªŒéªŒè¯ï¼Œå¢å¼ºäº†ç ”ç©¶ç»“æœçš„å¯ä¿¡åº¦ä¸è¯´æœåŠ›ã€‚\n",
      "\n",
      "### 3. **å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„ç»¼åˆåº”ç”¨ä¸æ·±å…¥åˆ†æ**\n",
      "   - **åˆ›æ–°é˜è¿°**ï¼šè®ºæ–‡ç»¼åˆè¿ç”¨äº†SFTã€RFTã€Online RFTã€DPOã€PPOå’ŒGRPOç­‰å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å¯¹æ¯ç§æ–¹æ³•è¿›è¡Œäº†ç»†è‡´çš„æ¨å¯¼ä¸åˆ†æï¼Œå±•ç¤ºäº†ç ”ç©¶æ–¹æ³•çš„ä¸°å¯Œæ€§å’Œç†è®ºæ·±åº¦ã€‚\n",
      "   - **å¯¹æ¯”åˆ†æ**ï¼šç›¸è¾ƒäºå¤šæ•°ç ”ç©¶ä»…èšç„¦äºæŸå‡ ç§æ–¹æ³•ï¼ŒDeepSeekè®ºæ–‡çš„å¤šæ–¹æ³•ç»¼åˆåº”ç”¨åŠæ·±å…¥å‰–æï¼Œæä¾›äº†æ›´ä¸ºå…¨é¢çš„ä¼˜åŒ–ç­–ç•¥ã€‚\n",
      "\n",
      "### 4. **Direct Preference Optimization (DPO)çš„å¼•å…¥ä¸åº”ç”¨**\n",
      "   - **åˆ›æ–°é˜è¿°**ï¼šé€šè¿‡å¼•å…¥DPOæ–¹æ³•ï¼Œç›´æ¥é’ˆå¯¹æ¨¡å‹åå¥½è¿›è¡Œä¼˜åŒ–ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½ã€‚\n",
      "   - **å¯¹æ¯”åˆ†æ**ï¼šç°æœ‰ç ”ç©¶è¾ƒå°‘æ¶‰åŠDPOæˆ–æœªæ·±å…¥æ¢è®¨å…¶åº”ç”¨ï¼ŒDeepSeekè®ºæ–‡åœ¨æ­¤æ–¹é¢çš„æ¢ç´¢ï¼Œå±•ç°äº†æ–¹æ³•åˆ›æ–°ä¸åº”ç”¨æ½œåŠ›ã€‚\n",
      "\n",
      "### 5. **å‰ç»æ€§æœªæ¥ç ”ç©¶æ–¹å‘çš„æ¢è®¨**\n",
      "   - **åˆ›æ–°é˜è¿°**ï¼šè®ºæ–‡ä¸ä»…å±€é™äºå½“å‰ç ”ç©¶æˆæœï¼Œè¿˜æ˜ç¡®æŒ‡å‡ºäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶çš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä½“ç°äº†ç ”ç©¶çš„æŒç»­æ€§ä¸å‰ç»æ€§ã€‚\n",
      "   - **å¯¹æ¯”åˆ†æ**ï¼šç›¸è¾ƒäºè®¸å¤šç ”ç©¶åœ¨ç»“è®ºéƒ¨åˆ†å¯¹æœªæ¥æ–¹å‘çš„æ¢è®¨ä¸è¶³ï¼ŒDeepSeekè®ºæ–‡çš„å‰ç»æ€§åˆ†æä¸ºåç»­ç ”ç©¶æä¾›äº†æ˜ç¡®æŒ‡å¯¼ã€‚\n",
      "\n",
      "### ç»¼åˆè¯„è¿°\n",
      "DeepSeekè®ºæ–‡åœ¨å¼€æ”¾è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†èƒ½åŠ›æå‡æ–¹é¢ï¼Œé€šè¿‡æ„å»ºé«˜è´¨é‡å¤šè¯­è¨€è¯­æ–™åº“ã€å®æ–½å…¨é¢é¢„è®­ç»ƒå®éªŒã€ç»¼åˆåº”ç”¨å¤šç§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€å¼•å…¥DPOä¼˜åŒ–ç­–ç•¥åŠå‰ç»æ€§ç ”ç©¶æ¢è®¨ï¼Œå±•ç°äº†å¤šé‡åˆ›æ–°ç‚¹ã€‚è¿™äº›åˆ›æ–°ä¸ä»…æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œäº¦ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•è®ºæŒ‡å¯¼ï¼Œå…·æœ‰æ·±è¿œçš„å­¦æœ¯å½±å“ä¸åº”ç”¨ä»·å€¼ã€‚\n",
      "è®ºæ–‡åŠ©æ‰‹ï¼šå†è§ï¼\n"
     ]
    }
   ],
   "source": [
    "chat_loop(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
